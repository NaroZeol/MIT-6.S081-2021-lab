# Lab: locks
## Memory allocator

该实验要求修改xv6的物理内存分配器，让每个CPU有自己的freelist而不是全局共用一个freelist，以改善高并发环境下分配物理内存时单一freelist性能表现不佳的问题。

实现起来相对容易，将原先的`kmem`结构体扩展，加上名字方便统计。同时用数组`kmems`替代原本维护物理内存分配的`kmem`。

初始化时使用`sprintf`为每个CPU的`kmem`的锁取上相应的名字。

先修改`kfree`，在释放时先关闭CPU中断，获取CPU id，根据id找到对应的`kmem`，将释放的块插入该链表即可。

修改`kalloc`，如果当前CPU有持有的空闲块的话，直接像往常一样分配出去即可。如果没有的话，尝试从其他CPU的空闲链表中“偷取”。也就是为其他cpu的空闲链表加上锁后再进行“偷取”。

在初始化时所有的空闲块都会分配给执行初始化操作的那个CPU。不过后续随着系统的运行，这个CPU上的空闲块会被其他CPU拿走。（或许在开始时平均分配会更好？

## Buffer cache

通过减少锁的互斥提高Buffer cache的性能。

最开始想做成多级分配器，即全局维护一个大的链表，每个桶再各自维护一个小的链表。

当要对buffer进行操作时，先尝试在每个桶中完成操作，如果没有空间再去全局链表中申请，这样可以大幅减少锁的竞争。

但是问题在于如果全局大链表也不够了。如何进行回收。

如果有一个恶意的负载一直对某个桶进行操作，导致该桶几乎拿走了所有的buffer。对其进行回收时，会导致全局链表的锁被长时间占用（因为几乎所有的buffer都在这里，要遍历很久）。这无疑是个很糟糕的情况。

如果改成回收固定个数，那么如何确定回收的个数又是一个新的问题。

最后还是改成了和上一个实验类似的多个freelist的形式。当不够时选择从其他桶中偷取。这个做法的问题在于随着操作系统的运行，锁的竞争变得越来越激烈（某些桶处于刚好够用的状态或者链表太长）。在将桶大小设置为13时第一次运行bcachetest时冲突只有0，在运行5次后冲突来到200多，10次后达到1000多，20次运行后达到2000多。虽然在修改桶大小和哈希函数后能缓解这个问题，但这确实不是个优雅的解决方案。（但至少能通过测试）

## 总结

这个lab理论难度不大。但为了排除死锁还是花了很多时间。

hints太长感觉没看懂要怎么做更合适。

总的来说这个lab的结果不怎么令人满意。。。